{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## Predict whether a mammogram mass is benign or malignant\n",
    "\n",
    "We'll be using the \"mammographic masses\" public dataset from the UCI repository (source: https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass)\n",
    "\n",
    "This data contains 961 instances of masses detected in mammograms, and contains the following attributes:\n",
    "\n",
    "\n",
    "   1. BI-RADS assessment: 1 to 5 (ordinal)  \n",
    "   2. Age: patient's age in years (integer)\n",
    "   3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\n",
    "   4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\n",
    "   5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\n",
    "   6. Severity: benign=0 or malignant=1 (binominal)\n",
    "   \n",
    "BI-RADS is an assesment of how confident the severity classification is; it is not a \"predictive\" attribute and so we will discard it. The age, shape, margin, and density attributes are the features that we will build our model with, and \"severity\" is the classification we will attempt to predict based on those attributes.\n",
    "\n",
    "Although \"shape\" and \"margin\" are nominal data types, which sklearn typically doesn't deal with well, they are close enough to ordinal that we shouldn't just discard them. The \"shape\" for example is ordered increasingly from round to irregular.\n",
    "\n",
    "A lot of unnecessary anguish and surgery arises from false positives arising from mammogram results. If we can build a better way to interpret them through supervised machine learning, it could improve a lot of lives.\n",
    "\n",
    "## Your assignment\n",
    "\n",
    "Apply several different supervised machine learning techniques to this data set, and see which one yields the highest accuracy as measured with K-Fold cross validation (K=10). Apply:\n",
    "\n",
    "* Decision tree\n",
    "* Random forest\n",
    "* KNN\n",
    "* Naive Bayes\n",
    "* SVM\n",
    "* Logistic Regression\n",
    "* And, as a bonus challenge, a neural network using Keras.\n",
    "\n",
    "The data needs to be cleaned; many rows contain missing data, and there may be erroneous data identifiable as outliers as well.\n",
    "\n",
    "Remember some techniques such as SVM also require the input data to be normalized first.\n",
    "\n",
    "Many techniques also have \"hyperparameters\" that need to be tuned. Once you identify a promising approach, see if you can make it even better by tuning its hyperparameters.\n",
    "\n",
    "I was able to achieve over 80% accuracy - can you beat that?\n",
    "\n",
    "Below I've set up an outline of a notebook for this project, with some guidance and hints. If you're up for a real challenge, try doing this project from scratch in a new, clean notebook!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's begin: prepare your data\n",
    "\n",
    "Start by importing the mammographic_masses.data.txt file into a Pandas dataframe (hint: use read_csv) and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>67</th>\n",
       "      <th>3</th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.1</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5  67  3 5.1 3.1  1\n",
       "0  4  43  1   1   ?  1\n",
       "1  5  58  4   5   3  1\n",
       "2  4  28  1   1   3  0\n",
       "3  5  74  1   5   ?  1\n",
       "4  4  65  1   ?   3  0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path_file = 'mammographic_masses.data.txt'\n",
    "inputData = pd.read_csv(path_file)\n",
    "inputData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you use the optional parmaters in read_csv to convert missing data (indicated by a ?) into NaN, and to add the appropriate column names (BI_RADS, age, shape, margin, density, and severity):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BI-RADS   Age  Shape  Margin  Density  Severity\n",
       "0      5.0  67.0    3.0     5.0      3.0         1\n",
       "1      4.0  43.0    1.0     1.0      NaN         1\n",
       "2      5.0  58.0    4.0     5.0      3.0         1\n",
       "3      4.0  28.0    1.0     1.0      3.0         0\n",
       "4      5.0  74.0    1.0     5.0      NaN         1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData = pd.read_csv(path_file, na_values='?',names= ['BI-RADS', 'Age', 'Shape', 'Margin','Density','Severity'])\n",
    "inputData.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate whether the data needs cleaning; your model is only as good as the data it's given. Hint: use describe() on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>959.000000</td>\n",
       "      <td>956.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>913.000000</td>\n",
       "      <td>885.000000</td>\n",
       "      <td>961.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.348279</td>\n",
       "      <td>55.487448</td>\n",
       "      <td>2.721505</td>\n",
       "      <td>2.796276</td>\n",
       "      <td>2.910734</td>\n",
       "      <td>0.463059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.783031</td>\n",
       "      <td>14.480131</td>\n",
       "      <td>1.242792</td>\n",
       "      <td>1.566546</td>\n",
       "      <td>0.380444</td>\n",
       "      <td>0.498893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BI-RADS         Age       Shape      Margin     Density    Severity\n",
       "count  959.000000  956.000000  930.000000  913.000000  885.000000  961.000000\n",
       "mean     4.348279   55.487448    2.721505    2.796276    2.910734    0.463059\n",
       "std      1.783031   14.480131    1.242792    1.566546    0.380444    0.498893\n",
       "min      0.000000   18.000000    1.000000    1.000000    1.000000    0.000000\n",
       "25%      4.000000   45.000000    2.000000    1.000000    3.000000    0.000000\n",
       "50%      4.000000   57.000000    3.000000    3.000000    3.000000    0.000000\n",
       "75%      5.000000   66.000000    4.000000    4.000000    3.000000    1.000000\n",
       "max     55.000000   96.000000    4.000000    5.000000    4.000000    1.000000"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few missing values in the data set. Before we just drop every row that's missing data, let's make sure we don't bias our data in doing so. Does there appear to be any sort of correlation to what sort of data has missing fields? If there were, we'd have to try and go back and fill that data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>6.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BI-RADS   Age  Shape  Margin  Density  Severity\n",
       "1        4.0  43.0    1.0     1.0      NaN         1\n",
       "4        5.0  74.0    1.0     5.0      NaN         1\n",
       "5        4.0  65.0    1.0     NaN      3.0         0\n",
       "6        4.0  70.0    NaN     NaN      3.0         0\n",
       "7        5.0  42.0    1.0     NaN      3.0         0\n",
       "..       ...   ...    ...     ...      ...       ...\n",
       "778      4.0  60.0    NaN     4.0      3.0         0\n",
       "819      4.0  35.0    3.0     NaN      2.0         0\n",
       "824      6.0  40.0    NaN     3.0      4.0         1\n",
       "884      5.0   NaN    4.0     4.0      3.0         1\n",
       "923      5.0   NaN    4.0     3.0      3.0         1\n",
       "\n",
       "[130 rows x 6 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the dataset's location with missing data values\n",
    "inputData.loc[(inputData['Age'].isnull())|\n",
    "              (inputData['Shape'].isnull())|\n",
    "              inputData['Margin'].isnull()|\n",
    "              inputData['Density'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the missing data seems randomly distributed, go ahead and drop rows with missing data. Hint: use dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BI-RADS</th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.393976</td>\n",
       "      <td>55.781928</td>\n",
       "      <td>2.781928</td>\n",
       "      <td>2.813253</td>\n",
       "      <td>2.915663</td>\n",
       "      <td>0.485542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.888371</td>\n",
       "      <td>14.671782</td>\n",
       "      <td>1.242361</td>\n",
       "      <td>1.567175</td>\n",
       "      <td>0.350936</td>\n",
       "      <td>0.500092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BI-RADS         Age       Shape      Margin     Density    Severity\n",
       "count  830.000000  830.000000  830.000000  830.000000  830.000000  830.000000\n",
       "mean     4.393976   55.781928    2.781928    2.813253    2.915663    0.485542\n",
       "std      1.888371   14.671782    1.242361    1.567175    0.350936    0.500092\n",
       "min      0.000000   18.000000    1.000000    1.000000    1.000000    0.000000\n",
       "25%      4.000000   46.000000    2.000000    1.000000    3.000000    0.000000\n",
       "50%      4.000000   57.000000    3.000000    3.000000    3.000000    0.000000\n",
       "75%      5.000000   66.000000    4.000000    4.000000    3.000000    1.000000\n",
       "max     55.000000   96.000000    4.000000    5.000000    4.000000    1.000000"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData.dropna(inplace=True)\n",
    "inputData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next you'll need to convert the Pandas dataframes into numpy arrays that can be used by scikit_learn. Create an array that extracts only the feature data we want to work with (age, shape, margin, and density) and another array that contains the classes (severity). You'll also need an array of the feature name labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5., 67.,  3.,  5.,  3.],\n",
       "       [ 5., 58.,  4.,  5.,  3.],\n",
       "       [ 4., 28.,  1.,  1.,  3.],\n",
       "       ...,\n",
       "       [ 4., 64.,  4.,  5.,  3.],\n",
       "       [ 5., 66.,  4.,  5.,  3.],\n",
       "       [ 4., 62.,  3.,  3.,  3.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets convert pandas dataframe to numpy arrays\n",
    "features = ['BI-RADS', 'Age', 'Shape', 'Margin','Density']\n",
    "# the next line of code converts the inputDat with the list of features to a numpy array\n",
    "all_feature = inputData[features].values\n",
    "\n",
    "# the next line of code converts the severity column to a numpy array\n",
    "all_classes = inputData['Severity'].values\n",
    "\n",
    "all_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our models require the input data to be normalized, so go ahead and normalize the attribute data. Hint: use preprocessing.StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3211177 ,  0.7650629 ,  0.17563638,  1.39618483,  0.24046607],\n",
       "       [ 0.3211177 ,  0.15127063,  0.98104077,  1.39618483,  0.24046607],\n",
       "       [-0.20875843, -1.89470363, -1.43517241, -1.157718  ,  0.24046607],\n",
       "       ...,\n",
       "       [-0.20875843,  0.56046548,  0.98104077,  1.39618483,  0.24046607],\n",
       "       [ 0.3211177 ,  0.69686376,  0.98104077,  1.39618483,  0.24046607],\n",
       "       [-0.20875843,  0.42406719,  0.17563638,  0.11923341,  0.24046607]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler as st\n",
    "#scaler = StandardScaler()\n",
    "scaler = st()\n",
    "scaledFeature = scaler.fit_transform(all_feature)\n",
    "scaledFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "Before moving to K-Fold cross validation and random forests, start by creating a single train/test split of our data. Set aside 75% for training, and 25% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  creating a single train/test split of our data. Set aside 75% for training, and 25% for testing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaledFeature, all_classes, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a DecisionTreeClassifier and fit it to your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  creating a DecisionTreeClassifier and fit it to your training data\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the resulting decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-5a9209dbea48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                          feature_names=features)  \n\u001b[0;32m     10\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, prog)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             self.__setattr__(\n\u001b[0;32m   1796\u001b[0m                 \u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m             )\n\u001b[0;32m   1799\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'create_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfrmt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydotplus\\graphviz.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1960\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "# dispalying the decision tree classifier\n",
    "\n",
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "from pydotplus import graph_from_dot_data\n",
    "\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(clf, out_file=dot_data,  \n",
    "                         feature_names=features)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy of the resulting decision tree model using your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.837620578778135"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing the score of decisio tree\n",
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of a single train/test split, use K-Fold cross validation to get a better measure of your model's accuracy (K=10). Hint: use model_selection.cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73015873 0.80952381 0.72580645 0.70967742 0.67741935 0.77419355\n",
      " 0.79032258 0.79032258 0.72580645 0.77419355]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(clf,X_train,y_train, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try a RandomForestClassifier instead. Does it perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8488745980707395"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForest = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "RandomForest.fit(X_train,y_train)\n",
    "RandomForest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "Next try using svm.SVC with a linear kernel. How does it compare to the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "C = 1.0\n",
    "svc = SVC(kernel='linear', C=C).fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8279742765273312"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "How about K-Nearest-Neighbors? Hint: use neighbors.KNeighborsClassifier - it's a lot easier than implementing KNN from scratch like we did earlier in the course. Start with a K of 10. K is an example of a hyperparameter - a parameter on the model itself which may need to be tuned for best results on your particular data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8215434083601286"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    ">>> KNN = KNeighborsClassifier(n_neighbors=10)\n",
    ">>> KNN.fit(X_train,y_train)\n",
    "KNN.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing K is tricky, so we can't discard KNN until we've tried different values of K. Write a for loop to run KNN with K values ranging from 1 to 50 and see if K makes a substantial difference. Make a note of the best performance you could get out of KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9228295819935691\n",
      "2 0.8456591639871383\n",
      "3 0.8665594855305466\n",
      "4 0.8360128617363344\n",
      "5 0.8392282958199357\n",
      "6 0.8344051446945338\n",
      "7 0.8263665594855305\n",
      "8 0.819935691318328\n",
      "9 0.8215434083601286\n",
      "10 0.8215434083601286\n",
      "11 0.819935691318328\n",
      "12 0.8247588424437299\n",
      "13 0.8183279742765274\n",
      "14 0.819935691318328\n",
      "15 0.8135048231511254\n",
      "16 0.8070739549839229\n",
      "17 0.8086816720257235\n",
      "18 0.8086816720257235\n",
      "19 0.8118971061093248\n",
      "20 0.819935691318328\n",
      "21 0.815112540192926\n",
      "22 0.815112540192926\n",
      "23 0.8135048231511254\n",
      "24 0.8038585209003215\n",
      "25 0.8086816720257235\n",
      "26 0.8086816720257235\n",
      "27 0.8022508038585209\n",
      "28 0.8038585209003215\n",
      "29 0.8086816720257235\n",
      "30 0.8070739549839229\n",
      "31 0.8006430868167203\n",
      "32 0.8022508038585209\n",
      "33 0.8022508038585209\n",
      "34 0.797427652733119\n",
      "35 0.7990353697749196\n",
      "36 0.7990353697749196\n",
      "37 0.7958199356913184\n",
      "38 0.7958199356913184\n",
      "39 0.797427652733119\n",
      "40 0.797427652733119\n",
      "41 0.8038585209003215\n",
      "42 0.8038585209003215\n",
      "43 0.8022508038585209\n",
      "44 0.8006430868167203\n",
      "45 0.8022508038585209\n",
      "46 0.8022508038585209\n",
      "47 0.8054662379421221\n",
      "48 0.8038585209003215\n",
      "49 0.8054662379421221\n"
     ]
    }
   ],
   "source": [
    "# using KNN with neighb\n",
    "def loopingK():\n",
    "    for i in range(1,50):\n",
    "        KNN = KNeighborsClassifier(n_neighbors=i)\n",
    "        KNN.fit(X_train,y_train)\n",
    "        print(i, KNN.score(X_train,y_train)) \n",
    "\n",
    "loopingK()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Now try naive_bayes.MultinomialNB. How does its accuracy stack up? Hint: you'll need to use MinMaxScaler to get the features in the range MultinomialNB requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.797427652733119"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "# y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "gnb.fit(X_train, y_train)\n",
    "gnb.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting SVM\n",
    "\n",
    "svm.SVC may perform differently with different kernels. The choice of kernel is an example of a \"hyperparamter.\" Try the rbf, sigmoid, and poly kernels and see what the best-performing kernel is. Do we have a new winner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.837620578778135"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svc with rbf\n",
    "svc = SVC(kernel='rbf', C=C).fit(X_train,y_train)\n",
    "svc.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.747588424437299"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='sigmoid', C=C).fit(X_train,y_train)\n",
    "svc.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327974276527331"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='poly', C=8).fit(X_train,y_train)\n",
    "svc.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We've tried all these fancy techniques, but fundamentally this is just a binary classification problem. Try Logisitic Regression, which is a simple way to tackling this sort of thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135048231511254"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logRegress= LogisticRegression(random_state=0)\n",
    "logRegress.fit(X_train,y_train)\n",
    "logRegress.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "As a bonus challenge, let's see if an artificial neural network can do even better. You can use Keras to set up a neural network with 1 binary output neuron and see how it performs. Don't be afraid to run a large number of epochs to train the model if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "from tensorflow.keras.optimizers import RMSprop # optimization function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting \n",
    "model = Sequential()\n",
    "model.add(Dense(5, activation = 'relu', input_shape=(5,)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 622 samples, validate on 208 samples\n",
      "Epoch 1/200\n",
      "622/622 - 1s - loss: 7.2465 - acc: 0.5161 - val_loss: 3.6433 - val_acc: 0.5096\n",
      "Epoch 2/200\n",
      "622/622 - 0s - loss: 3.4515 - acc: 0.5161 - val_loss: 2.9495 - val_acc: 0.5096\n",
      "Epoch 3/200\n",
      "622/622 - 0s - loss: 3.1198 - acc: 0.5161 - val_loss: 2.7411 - val_acc: 0.5096\n",
      "Epoch 4/200\n",
      "622/622 - 0s - loss: 2.8758 - acc: 0.5161 - val_loss: 2.5979 - val_acc: 0.5096\n",
      "Epoch 5/200\n",
      "622/622 - 0s - loss: 2.5082 - acc: 0.5161 - val_loss: 2.1182 - val_acc: 0.5096\n",
      "Epoch 6/200\n",
      "622/622 - 0s - loss: 1.9932 - acc: 0.5161 - val_loss: 1.6584 - val_acc: 0.5096\n",
      "Epoch 7/200\n",
      "622/622 - 0s - loss: 1.5611 - acc: 0.5161 - val_loss: 1.3876 - val_acc: 0.5096\n",
      "Epoch 8/200\n",
      "622/622 - 0s - loss: 1.3565 - acc: 0.5161 - val_loss: 1.2981 - val_acc: 0.5096\n",
      "Epoch 9/200\n",
      "622/622 - 0s - loss: 1.2614 - acc: 0.5161 - val_loss: 1.1883 - val_acc: 0.5096\n",
      "Epoch 10/200\n",
      "622/622 - 0s - loss: 1.1620 - acc: 0.5161 - val_loss: 1.1181 - val_acc: 0.5096\n",
      "Epoch 11/200\n",
      "622/622 - 0s - loss: 1.0786 - acc: 0.5161 - val_loss: 1.0597 - val_acc: 0.5096\n",
      "Epoch 12/200\n",
      "622/622 - 0s - loss: 1.0214 - acc: 0.5161 - val_loss: 1.0051 - val_acc: 0.5096\n",
      "Epoch 13/200\n",
      "622/622 - 0s - loss: 0.9682 - acc: 0.5161 - val_loss: 0.9530 - val_acc: 0.5096\n",
      "Epoch 14/200\n",
      "622/622 - 0s - loss: 0.9178 - acc: 0.5161 - val_loss: 0.9026 - val_acc: 0.5096\n",
      "Epoch 15/200\n",
      "622/622 - 0s - loss: 0.8703 - acc: 0.5161 - val_loss: 0.8572 - val_acc: 0.5096\n",
      "Epoch 16/200\n",
      "622/622 - 0s - loss: 0.8258 - acc: 0.5161 - val_loss: 0.8096 - val_acc: 0.5096\n",
      "Epoch 17/200\n",
      "622/622 - 0s - loss: 0.7788 - acc: 0.5145 - val_loss: 0.7628 - val_acc: 0.5144\n",
      "Epoch 18/200\n",
      "622/622 - 0s - loss: 0.7360 - acc: 0.5129 - val_loss: 0.7221 - val_acc: 0.5192\n",
      "Epoch 19/200\n",
      "622/622 - 0s - loss: 0.6993 - acc: 0.5161 - val_loss: 0.6856 - val_acc: 0.5144\n",
      "Epoch 20/200\n",
      "622/622 - 0s - loss: 0.6667 - acc: 0.5193 - val_loss: 0.6496 - val_acc: 0.5288\n",
      "Epoch 21/200\n",
      "622/622 - 0s - loss: 0.6358 - acc: 0.5579 - val_loss: 0.6170 - val_acc: 0.6058\n",
      "Epoch 22/200\n",
      "622/622 - 0s - loss: 0.6085 - acc: 0.5997 - val_loss: 0.5890 - val_acc: 0.6442\n",
      "Epoch 23/200\n",
      "622/622 - 0s - loss: 0.5855 - acc: 0.6688 - val_loss: 0.5662 - val_acc: 0.6923\n",
      "Epoch 24/200\n",
      "622/622 - 0s - loss: 0.5654 - acc: 0.7074 - val_loss: 0.5442 - val_acc: 0.7019\n",
      "Epoch 25/200\n",
      "622/622 - 0s - loss: 0.5476 - acc: 0.7219 - val_loss: 0.5260 - val_acc: 0.7356\n",
      "Epoch 26/200\n",
      "622/622 - 0s - loss: 0.5352 - acc: 0.7395 - val_loss: 0.5138 - val_acc: 0.7548\n",
      "Epoch 27/200\n",
      "622/622 - 0s - loss: 0.5438 - acc: 0.7476 - val_loss: 0.5038 - val_acc: 0.7740\n",
      "Epoch 28/200\n",
      "622/622 - 0s - loss: 0.5350 - acc: 0.7508 - val_loss: 0.4983 - val_acc: 0.7740\n",
      "Epoch 29/200\n",
      "622/622 - 0s - loss: 0.5290 - acc: 0.7492 - val_loss: 0.4938 - val_acc: 0.7740\n",
      "Epoch 30/200\n",
      "622/622 - 0s - loss: 0.5251 - acc: 0.7572 - val_loss: 0.4914 - val_acc: 0.7788\n",
      "Epoch 31/200\n",
      "622/622 - 0s - loss: 0.5216 - acc: 0.7572 - val_loss: 0.4875 - val_acc: 0.7788\n",
      "Epoch 32/200\n",
      "622/622 - 0s - loss: 0.5181 - acc: 0.7605 - val_loss: 0.4830 - val_acc: 0.7788\n",
      "Epoch 33/200\n",
      "622/622 - 0s - loss: 0.5150 - acc: 0.7605 - val_loss: 0.4796 - val_acc: 0.7788\n",
      "Epoch 34/200\n",
      "622/622 - 0s - loss: 0.5100 - acc: 0.7621 - val_loss: 0.4733 - val_acc: 0.7837\n",
      "Epoch 35/200\n",
      "622/622 - 0s - loss: 0.5073 - acc: 0.7653 - val_loss: 0.4684 - val_acc: 0.7837\n",
      "Epoch 36/200\n",
      "622/622 - 0s - loss: 0.5020 - acc: 0.7669 - val_loss: 0.4650 - val_acc: 0.7885\n",
      "Epoch 37/200\n",
      "622/622 - 0s - loss: 0.4986 - acc: 0.7749 - val_loss: 0.4614 - val_acc: 0.8029\n",
      "Epoch 38/200\n",
      "622/622 - 0s - loss: 0.4949 - acc: 0.7781 - val_loss: 0.4579 - val_acc: 0.8173\n",
      "Epoch 39/200\n",
      "622/622 - 0s - loss: 0.4920 - acc: 0.7830 - val_loss: 0.4569 - val_acc: 0.8269\n",
      "Epoch 40/200\n",
      "622/622 - 0s - loss: 0.4900 - acc: 0.7846 - val_loss: 0.4550 - val_acc: 0.8317\n",
      "Epoch 41/200\n",
      "622/622 - 0s - loss: 0.4862 - acc: 0.7894 - val_loss: 0.4526 - val_acc: 0.8365\n",
      "Epoch 42/200\n",
      "622/622 - 0s - loss: 0.4853 - acc: 0.7942 - val_loss: 0.4527 - val_acc: 0.8365\n",
      "Epoch 43/200\n",
      "622/622 - 0s - loss: 0.4822 - acc: 0.7942 - val_loss: 0.4500 - val_acc: 0.8365\n",
      "Epoch 44/200\n",
      "622/622 - 0s - loss: 0.4805 - acc: 0.7974 - val_loss: 0.4466 - val_acc: 0.8413\n",
      "Epoch 45/200\n",
      "622/622 - 0s - loss: 0.4783 - acc: 0.7974 - val_loss: 0.4421 - val_acc: 0.8413\n",
      "Epoch 46/200\n",
      "622/622 - 0s - loss: 0.4764 - acc: 0.8006 - val_loss: 0.4408 - val_acc: 0.8462\n",
      "Epoch 47/200\n",
      "622/622 - 0s - loss: 0.4745 - acc: 0.8006 - val_loss: 0.4383 - val_acc: 0.8510\n",
      "Epoch 48/200\n",
      "622/622 - 0s - loss: 0.4732 - acc: 0.7974 - val_loss: 0.4367 - val_acc: 0.8510\n",
      "Epoch 49/200\n",
      "622/622 - 0s - loss: 0.4711 - acc: 0.8023 - val_loss: 0.4345 - val_acc: 0.8558\n",
      "Epoch 50/200\n",
      "622/622 - 0s - loss: 0.4691 - acc: 0.8023 - val_loss: 0.4368 - val_acc: 0.8558\n",
      "Epoch 51/200\n",
      "622/622 - 0s - loss: 0.4675 - acc: 0.8006 - val_loss: 0.4311 - val_acc: 0.8558\n",
      "Epoch 52/200\n",
      "622/622 - 0s - loss: 0.4668 - acc: 0.8006 - val_loss: 0.4321 - val_acc: 0.8654\n",
      "Epoch 53/200\n",
      "622/622 - 0s - loss: 0.4642 - acc: 0.8006 - val_loss: 0.4275 - val_acc: 0.8606\n",
      "Epoch 54/200\n",
      "622/622 - 0s - loss: 0.4628 - acc: 0.8023 - val_loss: 0.4262 - val_acc: 0.8654\n",
      "Epoch 55/200\n",
      "622/622 - 0s - loss: 0.4621 - acc: 0.8023 - val_loss: 0.4269 - val_acc: 0.8606\n",
      "Epoch 56/200\n",
      "622/622 - 0s - loss: 0.4606 - acc: 0.8055 - val_loss: 0.4300 - val_acc: 0.8606\n",
      "Epoch 57/200\n",
      "622/622 - 0s - loss: 0.4595 - acc: 0.8087 - val_loss: 0.4331 - val_acc: 0.8606\n",
      "Epoch 58/200\n",
      "622/622 - 0s - loss: 0.4587 - acc: 0.8055 - val_loss: 0.4257 - val_acc: 0.8606\n",
      "Epoch 59/200\n",
      "622/622 - 0s - loss: 0.4567 - acc: 0.8039 - val_loss: 0.4712 - val_acc: 0.8606\n",
      "Epoch 60/200\n",
      "622/622 - 0s - loss: 0.4560 - acc: 0.8087 - val_loss: 0.4239 - val_acc: 0.8606\n",
      "Epoch 61/200\n",
      "622/622 - 0s - loss: 0.4558 - acc: 0.8087 - val_loss: 0.4300 - val_acc: 0.8606\n",
      "Epoch 62/200\n",
      "622/622 - 0s - loss: 0.4543 - acc: 0.8119 - val_loss: 0.4282 - val_acc: 0.8606\n",
      "Epoch 63/200\n",
      "622/622 - 0s - loss: 0.4533 - acc: 0.8103 - val_loss: 0.4712 - val_acc: 0.8606\n",
      "Epoch 64/200\n",
      "622/622 - 0s - loss: 0.4523 - acc: 0.8103 - val_loss: 0.4711 - val_acc: 0.8606\n",
      "Epoch 65/200\n",
      "622/622 - 0s - loss: 0.4515 - acc: 0.8119 - val_loss: 0.4725 - val_acc: 0.8606\n",
      "Epoch 66/200\n",
      "622/622 - 0s - loss: 0.4513 - acc: 0.8119 - val_loss: 0.5271 - val_acc: 0.8606\n",
      "Epoch 67/200\n",
      "622/622 - 0s - loss: 0.4505 - acc: 0.8103 - val_loss: 0.4661 - val_acc: 0.8654\n",
      "Epoch 68/200\n",
      "622/622 - 0s - loss: 0.4492 - acc: 0.8135 - val_loss: 0.4665 - val_acc: 0.8606\n",
      "Epoch 69/200\n",
      "622/622 - 0s - loss: 0.4495 - acc: 0.8119 - val_loss: 0.4665 - val_acc: 0.8606\n",
      "Epoch 70/200\n",
      "622/622 - 0s - loss: 0.4487 - acc: 0.8119 - val_loss: 0.4666 - val_acc: 0.8654\n",
      "Epoch 71/200\n",
      "622/622 - 0s - loss: 0.4470 - acc: 0.8119 - val_loss: 0.5246 - val_acc: 0.8606\n",
      "Epoch 72/200\n",
      "622/622 - 0s - loss: 0.4476 - acc: 0.8151 - val_loss: 0.5246 - val_acc: 0.8606\n",
      "Epoch 73/200\n",
      "622/622 - 0s - loss: 0.4459 - acc: 0.8135 - val_loss: 0.5241 - val_acc: 0.8606\n",
      "Epoch 74/200\n",
      "622/622 - 0s - loss: 0.4466 - acc: 0.8151 - val_loss: 0.5246 - val_acc: 0.8606\n",
      "Epoch 75/200\n",
      "622/622 - 0s - loss: 0.4453 - acc: 0.8151 - val_loss: 0.5229 - val_acc: 0.8606\n",
      "Epoch 76/200\n",
      "622/622 - 0s - loss: 0.4443 - acc: 0.8135 - val_loss: 0.4712 - val_acc: 0.8606\n",
      "Epoch 77/200\n",
      "622/622 - 0s - loss: 0.4440 - acc: 0.8151 - val_loss: 0.5226 - val_acc: 0.8654\n",
      "Epoch 78/200\n",
      "622/622 - 0s - loss: 0.4431 - acc: 0.8135 - val_loss: 0.4705 - val_acc: 0.8654\n",
      "Epoch 79/200\n",
      "622/622 - 0s - loss: 0.4434 - acc: 0.8151 - val_loss: 0.4792 - val_acc: 0.8606\n",
      "Epoch 80/200\n",
      "622/622 - 0s - loss: 0.4425 - acc: 0.8135 - val_loss: 0.4693 - val_acc: 0.8654\n",
      "Epoch 81/200\n",
      "622/622 - 0s - loss: 0.4441 - acc: 0.8135 - val_loss: 0.5214 - val_acc: 0.8606\n",
      "Epoch 82/200\n",
      "622/622 - 0s - loss: 0.4415 - acc: 0.8119 - val_loss: 0.4636 - val_acc: 0.8654\n",
      "Epoch 83/200\n",
      "622/622 - 0s - loss: 0.4407 - acc: 0.8135 - val_loss: 0.5212 - val_acc: 0.8606\n",
      "Epoch 84/200\n",
      "622/622 - 0s - loss: 0.4418 - acc: 0.8167 - val_loss: 0.4595 - val_acc: 0.8654\n",
      "Epoch 85/200\n",
      "622/622 - 0s - loss: 0.4403 - acc: 0.8151 - val_loss: 0.4581 - val_acc: 0.8654\n",
      "Epoch 86/200\n",
      "622/622 - 0s - loss: 0.4398 - acc: 0.8167 - val_loss: 0.4623 - val_acc: 0.8654\n",
      "Epoch 87/200\n",
      "622/622 - 0s - loss: 0.4399 - acc: 0.8135 - val_loss: 0.4653 - val_acc: 0.8654\n",
      "Epoch 88/200\n",
      "622/622 - 0s - loss: 0.4398 - acc: 0.8151 - val_loss: 0.4687 - val_acc: 0.8654\n",
      "Epoch 89/200\n",
      "622/622 - 0s - loss: 0.4410 - acc: 0.8183 - val_loss: 0.5192 - val_acc: 0.8606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "622/622 - 0s - loss: 0.4383 - acc: 0.8167 - val_loss: 0.4668 - val_acc: 0.8606\n",
      "Epoch 91/200\n",
      "622/622 - 0s - loss: 0.4391 - acc: 0.8167 - val_loss: 0.4617 - val_acc: 0.8654\n",
      "Epoch 92/200\n",
      "622/622 - 0s - loss: 0.4378 - acc: 0.8215 - val_loss: 0.4673 - val_acc: 0.8654\n",
      "Epoch 93/200\n",
      "622/622 - 0s - loss: 0.4381 - acc: 0.8183 - val_loss: 0.4692 - val_acc: 0.8654\n",
      "Epoch 94/200\n",
      "622/622 - 0s - loss: 0.4378 - acc: 0.8183 - val_loss: 0.4579 - val_acc: 0.8654\n",
      "Epoch 95/200\n",
      "622/622 - 0s - loss: 0.4366 - acc: 0.8232 - val_loss: 0.5186 - val_acc: 0.8606\n",
      "Epoch 96/200\n",
      "622/622 - 0s - loss: 0.4376 - acc: 0.8183 - val_loss: 0.4543 - val_acc: 0.8702\n",
      "Epoch 97/200\n",
      "622/622 - 0s - loss: 0.4365 - acc: 0.8248 - val_loss: 0.4575 - val_acc: 0.8654\n",
      "Epoch 98/200\n",
      "622/622 - 0s - loss: 0.4356 - acc: 0.8248 - val_loss: 0.4587 - val_acc: 0.8606\n",
      "Epoch 99/200\n",
      "622/622 - 0s - loss: 0.4362 - acc: 0.8248 - val_loss: 0.4550 - val_acc: 0.8702\n",
      "Epoch 100/200\n",
      "622/622 - 0s - loss: 0.4361 - acc: 0.8248 - val_loss: 0.4560 - val_acc: 0.8654\n",
      "Epoch 101/200\n",
      "622/622 - 0s - loss: 0.4350 - acc: 0.8264 - val_loss: 0.4529 - val_acc: 0.8702\n",
      "Epoch 102/200\n",
      "622/622 - 0s - loss: 0.4344 - acc: 0.8280 - val_loss: 0.4576 - val_acc: 0.8702\n",
      "Epoch 103/200\n",
      "622/622 - 0s - loss: 0.4335 - acc: 0.8264 - val_loss: 0.4563 - val_acc: 0.8702\n",
      "Epoch 104/200\n",
      "622/622 - 0s - loss: 0.4337 - acc: 0.8248 - val_loss: 0.4529 - val_acc: 0.8702\n",
      "Epoch 105/200\n",
      "622/622 - 0s - loss: 0.4338 - acc: 0.8264 - val_loss: 0.4519 - val_acc: 0.8702\n",
      "Epoch 106/200\n",
      "622/622 - 0s - loss: 0.4331 - acc: 0.8264 - val_loss: 0.4566 - val_acc: 0.8702\n",
      "Epoch 107/200\n",
      "622/622 - 0s - loss: 0.4319 - acc: 0.8280 - val_loss: 0.4613 - val_acc: 0.8702\n",
      "Epoch 108/200\n",
      "622/622 - 0s - loss: 0.4345 - acc: 0.8264 - val_loss: 0.4538 - val_acc: 0.8702\n",
      "Epoch 109/200\n",
      "622/622 - 0s - loss: 0.4310 - acc: 0.8312 - val_loss: 0.4524 - val_acc: 0.8702\n",
      "Epoch 110/200\n",
      "622/622 - 0s - loss: 0.4309 - acc: 0.8312 - val_loss: 0.4536 - val_acc: 0.8702\n",
      "Epoch 111/200\n",
      "622/622 - 0s - loss: 0.4314 - acc: 0.8312 - val_loss: 0.4593 - val_acc: 0.8702\n",
      "Epoch 112/200\n",
      "622/622 - 0s - loss: 0.4297 - acc: 0.8280 - val_loss: 0.4587 - val_acc: 0.8702\n",
      "Epoch 113/200\n",
      "622/622 - 0s - loss: 0.4292 - acc: 0.8312 - val_loss: 0.4585 - val_acc: 0.8702\n",
      "Epoch 114/200\n",
      "622/622 - 0s - loss: 0.4299 - acc: 0.8296 - val_loss: 0.4507 - val_acc: 0.8702\n",
      "Epoch 115/200\n",
      "622/622 - 0s - loss: 0.4300 - acc: 0.8344 - val_loss: 0.4524 - val_acc: 0.8702\n",
      "Epoch 116/200\n",
      "622/622 - 0s - loss: 0.4289 - acc: 0.8344 - val_loss: 0.4536 - val_acc: 0.8702\n",
      "Epoch 117/200\n",
      "622/622 - 0s - loss: 0.4293 - acc: 0.8344 - val_loss: 0.4543 - val_acc: 0.8702\n",
      "Epoch 118/200\n",
      "622/622 - 0s - loss: 0.4295 - acc: 0.8328 - val_loss: 0.4524 - val_acc: 0.8702\n",
      "Epoch 119/200\n",
      "622/622 - 0s - loss: 0.4282 - acc: 0.8312 - val_loss: 0.4546 - val_acc: 0.8702\n",
      "Epoch 120/200\n",
      "622/622 - 0s - loss: 0.4273 - acc: 0.8328 - val_loss: 0.4522 - val_acc: 0.8702\n",
      "Epoch 121/200\n",
      "622/622 - 0s - loss: 0.4274 - acc: 0.8328 - val_loss: 0.4541 - val_acc: 0.8702\n",
      "Epoch 122/200\n",
      "622/622 - 0s - loss: 0.4271 - acc: 0.8328 - val_loss: 0.4605 - val_acc: 0.8702\n",
      "Epoch 123/200\n",
      "622/622 - 0s - loss: 0.4288 - acc: 0.8296 - val_loss: 0.4480 - val_acc: 0.8654\n",
      "Epoch 124/200\n",
      "622/622 - 0s - loss: 0.4260 - acc: 0.8264 - val_loss: 0.4486 - val_acc: 0.8654\n",
      "Epoch 125/200\n",
      "622/622 - 0s - loss: 0.4253 - acc: 0.8264 - val_loss: 0.4510 - val_acc: 0.8702\n",
      "Epoch 126/200\n",
      "622/622 - 0s - loss: 0.4283 - acc: 0.8280 - val_loss: 0.4501 - val_acc: 0.8654\n",
      "Epoch 127/200\n",
      "622/622 - 0s - loss: 0.4251 - acc: 0.8280 - val_loss: 0.4516 - val_acc: 0.8702\n",
      "Epoch 128/200\n",
      "622/622 - 0s - loss: 0.4267 - acc: 0.8264 - val_loss: 0.4483 - val_acc: 0.8654\n",
      "Epoch 129/200\n",
      "622/622 - 0s - loss: 0.4245 - acc: 0.8280 - val_loss: 0.4490 - val_acc: 0.8654\n",
      "Epoch 130/200\n",
      "622/622 - 0s - loss: 0.4248 - acc: 0.8296 - val_loss: 0.4525 - val_acc: 0.8702\n",
      "Epoch 131/200\n",
      "622/622 - 0s - loss: 0.4239 - acc: 0.8280 - val_loss: 0.4521 - val_acc: 0.8702\n",
      "Epoch 132/200\n",
      "622/622 - 0s - loss: 0.4237 - acc: 0.8296 - val_loss: 0.4490 - val_acc: 0.8702\n",
      "Epoch 133/200\n",
      "622/622 - 0s - loss: 0.4234 - acc: 0.8280 - val_loss: 0.4575 - val_acc: 0.8702\n",
      "Epoch 134/200\n",
      "622/622 - 0s - loss: 0.4233 - acc: 0.8328 - val_loss: 0.4559 - val_acc: 0.8702\n",
      "Epoch 135/200\n",
      "622/622 - 0s - loss: 0.4391 - acc: 0.8328 - val_loss: 0.5638 - val_acc: 0.8606\n",
      "Epoch 136/200\n",
      "622/622 - 0s - loss: 0.4384 - acc: 0.8328 - val_loss: 0.5618 - val_acc: 0.8606\n",
      "Epoch 137/200\n",
      "622/622 - 0s - loss: 0.4375 - acc: 0.8328 - val_loss: 0.5572 - val_acc: 0.8606\n",
      "Epoch 138/200\n",
      "622/622 - 0s - loss: 0.4360 - acc: 0.8328 - val_loss: 0.5550 - val_acc: 0.8654\n",
      "Epoch 139/200\n",
      "622/622 - 0s - loss: 0.4366 - acc: 0.8328 - val_loss: 0.5572 - val_acc: 0.8606\n",
      "Epoch 140/200\n",
      "622/622 - 0s - loss: 0.4332 - acc: 0.8328 - val_loss: 0.5564 - val_acc: 0.8654\n",
      "Epoch 141/200\n",
      "622/622 - 0s - loss: 0.4326 - acc: 0.8360 - val_loss: 0.5541 - val_acc: 0.8654\n",
      "Epoch 142/200\n",
      "622/622 - 0s - loss: 0.4325 - acc: 0.8328 - val_loss: 0.5578 - val_acc: 0.8606\n",
      "Epoch 143/200\n",
      "622/622 - 0s - loss: 0.4308 - acc: 0.8312 - val_loss: 0.5577 - val_acc: 0.8654\n",
      "Epoch 144/200\n",
      "622/622 - 0s - loss: 0.4300 - acc: 0.8328 - val_loss: 0.5523 - val_acc: 0.8606\n",
      "Epoch 145/200\n",
      "622/622 - 0s - loss: 0.4281 - acc: 0.8344 - val_loss: 0.5504 - val_acc: 0.8654\n",
      "Epoch 146/200\n",
      "622/622 - 0s - loss: 0.4281 - acc: 0.8312 - val_loss: 0.5514 - val_acc: 0.8606\n",
      "Epoch 147/200\n",
      "622/622 - 0s - loss: 0.4271 - acc: 0.8360 - val_loss: 0.5567 - val_acc: 0.8606\n",
      "Epoch 148/200\n",
      "622/622 - 0s - loss: 0.4260 - acc: 0.8344 - val_loss: 0.5532 - val_acc: 0.8606\n",
      "Epoch 149/200\n",
      "622/622 - 0s - loss: 0.4255 - acc: 0.8328 - val_loss: 0.5511 - val_acc: 0.8606\n",
      "Epoch 150/200\n",
      "622/622 - 0s - loss: 0.4260 - acc: 0.8344 - val_loss: 0.5548 - val_acc: 0.8558\n",
      "Epoch 151/200\n",
      "622/622 - 0s - loss: 0.4257 - acc: 0.8328 - val_loss: 0.5542 - val_acc: 0.8606\n",
      "Epoch 152/200\n",
      "622/622 - 0s - loss: 0.4235 - acc: 0.8328 - val_loss: 0.5540 - val_acc: 0.8654\n",
      "Epoch 153/200\n",
      "622/622 - 0s - loss: 0.4235 - acc: 0.8312 - val_loss: 0.5601 - val_acc: 0.8558\n",
      "Epoch 154/200\n",
      "622/622 - 0s - loss: 0.4232 - acc: 0.8328 - val_loss: 0.5521 - val_acc: 0.8654\n",
      "Epoch 155/200\n",
      "622/622 - 0s - loss: 0.4221 - acc: 0.8328 - val_loss: 0.5588 - val_acc: 0.8558\n",
      "Epoch 156/200\n",
      "622/622 - 0s - loss: 0.4222 - acc: 0.8312 - val_loss: 0.5536 - val_acc: 0.8654\n",
      "Epoch 157/200\n",
      "622/622 - 0s - loss: 0.4215 - acc: 0.8312 - val_loss: 0.5531 - val_acc: 0.8654\n",
      "Epoch 158/200\n",
      "622/622 - 0s - loss: 0.4214 - acc: 0.8328 - val_loss: 0.5524 - val_acc: 0.8654\n",
      "Epoch 159/200\n",
      "622/622 - 0s - loss: 0.4215 - acc: 0.8312 - val_loss: 0.5536 - val_acc: 0.8654\n",
      "Epoch 160/200\n",
      "622/622 - 0s - loss: 0.4197 - acc: 0.8344 - val_loss: 0.5565 - val_acc: 0.8654\n",
      "Epoch 161/200\n",
      "622/622 - 0s - loss: 0.4207 - acc: 0.8312 - val_loss: 0.5633 - val_acc: 0.8654\n",
      "Epoch 162/200\n",
      "622/622 - 0s - loss: 0.4201 - acc: 0.8360 - val_loss: 0.6145 - val_acc: 0.8654\n",
      "Epoch 163/200\n",
      "622/622 - 0s - loss: 0.4196 - acc: 0.8344 - val_loss: 0.5542 - val_acc: 0.8654\n",
      "Epoch 164/200\n",
      "622/622 - 0s - loss: 0.4194 - acc: 0.8344 - val_loss: 0.5507 - val_acc: 0.8606\n",
      "Epoch 165/200\n",
      "622/622 - 0s - loss: 0.4182 - acc: 0.8360 - val_loss: 0.6143 - val_acc: 0.8654\n",
      "Epoch 166/200\n",
      "622/622 - 0s - loss: 0.4190 - acc: 0.8328 - val_loss: 0.5530 - val_acc: 0.8606\n",
      "Epoch 167/200\n",
      "622/622 - 0s - loss: 0.4184 - acc: 0.8344 - val_loss: 0.5530 - val_acc: 0.8606\n",
      "Epoch 168/200\n",
      "622/622 - 0s - loss: 0.4236 - acc: 0.8376 - val_loss: 0.5525 - val_acc: 0.8606\n",
      "Epoch 169/200\n",
      "622/622 - 0s - loss: 0.4174 - acc: 0.8376 - val_loss: 0.5542 - val_acc: 0.8606\n",
      "Epoch 170/200\n",
      "622/622 - 0s - loss: 0.4169 - acc: 0.8360 - val_loss: 0.5544 - val_acc: 0.8606\n",
      "Epoch 171/200\n",
      "622/622 - 0s - loss: 0.4169 - acc: 0.8376 - val_loss: 0.5556 - val_acc: 0.8606\n",
      "Epoch 172/200\n",
      "622/622 - 0s - loss: 0.4167 - acc: 0.8360 - val_loss: 0.5548 - val_acc: 0.8606\n",
      "Epoch 173/200\n",
      "622/622 - 0s - loss: 0.4164 - acc: 0.8360 - val_loss: 0.5597 - val_acc: 0.8606\n",
      "Epoch 174/200\n",
      "622/622 - 0s - loss: 0.4169 - acc: 0.8376 - val_loss: 0.5565 - val_acc: 0.8606\n",
      "Epoch 175/200\n",
      "622/622 - 0s - loss: 0.4166 - acc: 0.8392 - val_loss: 0.5681 - val_acc: 0.8606\n",
      "Epoch 176/200\n",
      "622/622 - 0s - loss: 0.4168 - acc: 0.8392 - val_loss: 0.6157 - val_acc: 0.8606\n",
      "Epoch 177/200\n",
      "622/622 - 0s - loss: 0.4163 - acc: 0.8376 - val_loss: 0.5612 - val_acc: 0.8606\n",
      "Epoch 178/200\n",
      "622/622 - 0s - loss: 0.4165 - acc: 0.8392 - val_loss: 0.5585 - val_acc: 0.8606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/200\n",
      "622/622 - 0s - loss: 0.4153 - acc: 0.8408 - val_loss: 0.5631 - val_acc: 0.8606\n",
      "Epoch 180/200\n",
      "622/622 - 0s - loss: 0.4356 - acc: 0.8376 - val_loss: 0.5571 - val_acc: 0.8606\n",
      "Epoch 181/200\n",
      "622/622 - 0s - loss: 0.4336 - acc: 0.8376 - val_loss: 0.5649 - val_acc: 0.8606\n",
      "Epoch 182/200\n",
      "622/622 - 0s - loss: 0.4337 - acc: 0.8392 - val_loss: 0.5549 - val_acc: 0.8606\n",
      "Epoch 183/200\n",
      "622/622 - 0s - loss: 0.4190 - acc: 0.8424 - val_loss: 0.5544 - val_acc: 0.8558\n",
      "Epoch 184/200\n",
      "622/622 - 0s - loss: 0.4152 - acc: 0.8424 - val_loss: 0.5540 - val_acc: 0.8558\n",
      "Epoch 185/200\n",
      "622/622 - 0s - loss: 0.4151 - acc: 0.8424 - val_loss: 0.5551 - val_acc: 0.8558\n",
      "Epoch 186/200\n",
      "622/622 - 0s - loss: 0.4154 - acc: 0.8424 - val_loss: 0.5545 - val_acc: 0.8558\n",
      "Epoch 187/200\n",
      "622/622 - 0s - loss: 0.4149 - acc: 0.8392 - val_loss: 0.5552 - val_acc: 0.8654\n",
      "Epoch 188/200\n",
      "622/622 - 0s - loss: 0.4149 - acc: 0.8441 - val_loss: 0.5562 - val_acc: 0.8606\n",
      "Epoch 189/200\n",
      "622/622 - 0s - loss: 0.4148 - acc: 0.8424 - val_loss: 0.5571 - val_acc: 0.8654\n",
      "Epoch 190/200\n",
      "622/622 - 0s - loss: 0.4155 - acc: 0.8457 - val_loss: 0.6140 - val_acc: 0.8606\n",
      "Epoch 191/200\n",
      "622/622 - 0s - loss: 0.4147 - acc: 0.8441 - val_loss: 0.6153 - val_acc: 0.8654\n",
      "Epoch 192/200\n",
      "622/622 - 0s - loss: 0.4141 - acc: 0.8441 - val_loss: 0.6149 - val_acc: 0.8654\n",
      "Epoch 193/200\n",
      "622/622 - 0s - loss: 0.4146 - acc: 0.8424 - val_loss: 0.5555 - val_acc: 0.8606\n",
      "Epoch 194/200\n",
      "622/622 - 0s - loss: 0.4131 - acc: 0.8441 - val_loss: 0.5601 - val_acc: 0.8606\n",
      "Epoch 195/200\n",
      "622/622 - 0s - loss: 0.4132 - acc: 0.8441 - val_loss: 0.6155 - val_acc: 0.8606\n",
      "Epoch 196/200\n",
      "622/622 - 0s - loss: 0.4135 - acc: 0.8441 - val_loss: 0.6152 - val_acc: 0.8606\n",
      "Epoch 197/200\n",
      "622/622 - 0s - loss: 0.4146 - acc: 0.8441 - val_loss: 0.6153 - val_acc: 0.8606\n",
      "Epoch 198/200\n",
      "622/622 - 0s - loss: 0.4128 - acc: 0.8457 - val_loss: 0.5619 - val_acc: 0.8606\n",
      "Epoch 199/200\n",
      "622/622 - 0s - loss: 0.4127 - acc: 0.8424 - val_loss: 0.6159 - val_acc: 0.8654\n",
      "Epoch 200/200\n",
      "622/622 - 0s - loss: 0.4133 - acc: 0.8489 - val_loss: 0.5578 - val_acc: 0.8606\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "                    batch_size=83,\n",
    "                    epochs=200,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Do we have a winner?\n",
    "\n",
    "Which model, and which choice of hyperparameters, performed the best? Feel free to share your results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neural network\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
